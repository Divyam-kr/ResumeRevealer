{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T04:41:37.287840400Z",
     "start_time": "2024-03-02T04:41:37.249842800Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from datetime import datetime\n",
    "import json\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import io\n",
    "import base64\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "\n",
    "chat_llm = ChatOpenAI(model='gpt-3.5-turbo',temperature=0.6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass Resume into single text and extract the details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "resume = \"\"\" Jainil Patel\n",
    "jainil24680@gmail.com 7774036728 @ linkedin.com/in/jainil-patel-2857ab202/\n",
    "\n",
    "\n",
    "© github.com/astro215\n",
    "\n",
    "EDUCATION\n",
    "\n",
    "Symbiosis Institute of Technology Aug 2021 - Jul 2025 | Pune, India\n",
    "B.Tech Artificial Intelligence and Machine Learning.\n",
    "\n",
    "SKILLS\n",
    "Languages: ML/AI:\n",
    "Python, C++, SQL Tensorflow , PyTorch, Numpy, Pandas, Keras ,\n",
    "OpenCV\n",
    "Web Technologies:\n",
    "Full Stack , HTML , CSS , JavaScript , React.js , App Development:\n",
    "Node.js , Express.js , FastAPI , MERN stack , Flask. React Native , Flutter\n",
    "Data Visualization Miscellaneous:\n",
    "PowerBi , Tableau Git , Linux , PyCharm, Latex , MongoDB\n",
    "\n",
    "PROFESSIONAL EXPERIENCE\n",
    "\n",
    "Idea Foundation 2 Jul 2023 - Dec 2023 | Pune, India\n",
    "Data Analyst - PowerBi , Tableau\n",
    "\n",
    "« Developed an interactive dashboard presenting individual student reports, utilizing data from an NGO across\n",
    "multiple centers.\n",
    "« Enhanced donor impact by employing creative data visualization techniques that vividly showcase the positive\n",
    "outcomes of the NGO's educational initiatives.\n",
    "Integrated interactive features into the dashboard, providing donors with a dynamic and engaging experience,\n",
    "fostering a deeper understanding of the meaningful contributions to student education.\n",
    "\n",
    "PROJECTS\n",
    "\n",
    "Legal Bot - Legal Text Summarization using NLP 2\n",
    "Python , TensorFlow , PyTorch , React Native , JavaScript , Fast API (Docker) , Firebase , Hugging Face\n",
    "« Orchestrated the training of models to distill intricate legal texts into digestible summaries, enhancing overall\n",
    "understanding.\n",
    "« Implemented the deployment of the Language Model (LLM) through FastAPI, seamlessly integrating it into a\n",
    "user-friendly React Native app for an optimized user experience.\n",
    "« Spearheaded the development of a mobile app employing advanced NLP techniques, revolutionizing the\n",
    "interpretation of legal jargon and enabling effortless extraction of crucial information from complex\n",
    "documents.\n",
    "\n",
    "Avifauna Acoustic Detection 2\n",
    "Python , TensorFlow , Streamlit\n",
    "« Spearheaded the development of advanced ML models, including Convolutional Neural Networks (CNNs) and\n",
    "Recurrent Neural Networks (RNNs), to achieve accurate bird species recognition.\n",
    "« Demonstrated forward-thinking innovation by envisioning a future where real-time bird recognition can be\n",
    "\n",
    "seamlessly achieved through smartphones. Emphasized collaboration to enrich data and improve the accuracy\n",
    "of avifauna identification.\n",
    "Made a significant impact on conservation efforts by actively contributing to bird population monitoring and\n",
    "behavior study. Showcased a strong commitment to ornithology through the application of cutting-edge ML\n",
    "techniques, furthering the cause of avian conservation.\n",
    "Resting, and cognitive state EEG signal classification of multiple subject-driven states. 2\n",
    "Python , TensorFlow , MNE (library) , Streamlit\n",
    "« Implemented EEG signal processing with a focus on preprocessing using the MNE library, emphasizing\n",
    "effective signal processing techniques.\n",
    "« Applied Supervised Machine Learning and Deep Learning for state classification, contributing to the\n",
    "understanding of EEG signal patterns and their correlation with cognitive states.\n",
    "« Conducted a comprehensive comparative analysis of various classification models, aiming to identify the most\n",
    "robust and accurate approach for EEG signal classification.\n",
    "« Engaged in ongoing research, actively contributing to a research paper. This involves exploring novel\n",
    "methodologies, staying at the forefront of EEG signal processing advancements, and making valuable\n",
    "contributions to the scientific community.\n",
    "\n",
    "ACHIEVEMENTS\n",
    "\n",
    "GGP-PAAI Student conference 2\n",
    "Presented research paper in GGP-PAAI Student's conference in partnership with Aston University(UK)\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T12:23:44.974706300Z",
     "start_time": "2024-03-01T12:23:44.960664500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "resume2 =\"\"\"\n",
    "\n",
    "Praxal Patel\n",
    "\n",
    "(516) 707-1006 | praxxals@gmail.com | linkedin.com/in/praxal\n",
    "\n",
    "EDUCATION\n",
    "New York University, Center For Data Science (GPA: 3.91/4.0) New York, NY\n",
    "Master of Science in Data Science May 2021\n",
    "? Relevant Coursework: Probability and Statistics, Machine Learning, Natural Language Understanding, Big Data, Deep\n",
    "Learning\n",
    "\n",
    "Institute of Technology, Nirma University (GPA: 3.8/4.0) India\n",
    "Bachelors of Technology in Computer Engineering May 2019\n",
    "? Relevant Coursework: Deep Learning, Machine Learning, Calculus, Linear Algebra, Algorithms, Cloud Computing\n",
    "\n",
    "WORK EXPERIENCE\n",
    "Revelio Labs New York, New York\n",
    "Data Scientist Jul 2021 - Present\n",
    "? Employed an innovative approach to build company embeddings using Graph ML algorithms like Node2Vec.\n",
    "? Working towards deploying a salary prediction model using Bayesian Additive Regression Trees.\n",
    "? Deliver custom client requests by curating and structuring unstructured public profile and job postings data through\n",
    "the use of proprietary algorithms.\n",
    "\n",
    "Coursera Mountain View, CA\n",
    "Marketing Data Scientist Intern: ML Group Oct 2020 - Dec 2020\n",
    "? Formulated a Health Dashboard to gauge continual performance of Coursera's Degree Recruitment Engine and built a\n",
    "system for automated hold-out sets for A/B/C tests\n",
    "? Revised the Degree Forecasting model by leveraging a Bayesian approach to enhance prediction estimates of final\n",
    "application submitted for Coursera degrees\n",
    "\n",
    "Wellness Space India\n",
    "Data Analyst | Technical Consultant Jan 2019 - Jun 2019\n",
    "? Engaged in studying Heart Rate Variability through 24-hours ECG signal data by developing SVM and LSTM models\n",
    "to predict a person's state of emotional arousal and analyzed key parameters associated with mental stress\n",
    "? Deployed a self-monitoring application to help clients monitor stress levels and comprehend effect of various activities\n",
    "on heart rate; Performed anomaly detection on the ECG data for artefact correction\n",
    "\n",
    "SKILLS & INTERESTS\n",
    "? Tools & Technologies: Scikit-Learn, Tensorflow, Keras, PyTorch, Scipy, PySpark, NumPy, Pandas, Matplotlib, Plotly,\n",
    "GCP, AWS\n",
    "? Programming Languages: Python, SQL, R, Java, C++, JavaScript, Hadoop, Spark, Hive\n",
    "\n",
    "ACADEMIC PROJECTS\n",
    "Impact of Career Development Services in Career Outcomes Sep 2020 - Dec 2020\n",
    "? Quantified impact of NYU Wasserman Center for Career Development on students’ actual career outcomes\n",
    "? Designed a framework to determine most important career coaching activities by developing Logistic Regression\n",
    "(78% accuracy) and Decision Trees (87% accuracy) models having \"Job Secure date\" as target variable\n",
    "\n",
    "Evaluating Summarization Tasks Using Sentence-BERT Mar 2020 - May 2020\n",
    "? Devised a novel metric by employing sentence embeddings from SentenceBERT for evaluation of Summarization\n",
    "Tasks (Dataset- 226,711 BBC news articles)\n",
    "? Validated SentenceBERT_Score correlates better to human evaluation than traditional evaluation metrics like ROUGE\n",
    "and BLEU\n",
    "\n",
    "Diabetic Retinopathy Detection Using Deep Learning Jan 2018 - Dec 2018\n",
    "? Identified Hard Exudates, Soft Exudates, Microaneurysm and Hemorrhages as key factors for detection; deployed\n",
    "CNN models to identify Retinopathy (Sensitivity-0.94) and leveraged the Ensemble Method to ascertain stage of\n",
    "Retinopathy\n",
    "? Performed Data Augmentation and Image Segmentation leveraging Attention UNet; Conducted experiments for\n",
    "generalization on datasets Messidor (1200 images), DiaretDB0(130 images) and DiaretDB1(84 images)\n",
    "\n",
    "Job Recommendation Engine Oct 2019 - Dec 2019\n",
    "? Leveraged Natural Language Toolkit (NLTK 3.4) for extracting keywords about pertinent skills from job descriptions\n",
    "and resumes\n",
    "? Developed a Recommendation Engine by computing Cosine Similarity and utilized Hit Ratio for evaluating\n",
    "performance of system- 46% hit rate increase over randomized recommendations for 100 recommendations\n",
    "\n",
    "Optimal Location Prediction for Emergency Stations Jul 2018 - Jan 2019\n",
    "? Formulated ML/DL Models to identify best suitable model for Travel Time Estimation; Travel Time estimated from\n",
    "XGBoost (RMSE: 42 seconds) was leveraged to drive K-Medoids for predicting optimal locations\n",
    "? Decreased turnaround time along with reduced utility of resources; for Staten Island: average time cut down by 6\n",
    "seconds utilizing 14 Fire Stations in comparison to 19 actual stations\n",
    "\n",
    "POSITION OF RESPONSIBILITY\n",
    "? Junior Data Scientist at NYU CDS responsible for classifying Neuro Typical and Atypical population under Prof. Alec\n",
    "Marantz\n",
    "? Research Assistant at NYUAD - Understanding Indonesia's scorched earth policy using news and satellite data\n",
    "? Teaching Fellow for Data Science Bootcamp at NYU STERN under Prof. Benjamin Zweig\n",
    "? Junior Data Scientist under Prof. Angela Radulescu responsible for characterizing how humans visually represent\n",
    "objects and interpreted the difference between human representation and neural network representation\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T04:41:41.705255300Z",
     "start_time": "2024-03-02T04:41:41.682247400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Template for extracting the details from the resume"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instruction Template "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "template_i = \"\"\" \n",
    "For the following text, extract the following information:\n",
    "\n",
    "Warning: Don't greet or write any introduction. Just start with the answer to the prompts. Do as per the instructions given in the prompt. If you don't know the answer, leave that part (keep blank) and move to the next part.\n",
    "\n",
    "1. Education: Extract the name of the all universities/colleges attended by the candidate with there CGPA.\n",
    "\n",
    "\n",
    "2. Work: Extract all organization names where he/she has worked along with the position held, and the duration of employment.\n",
    "            Predicted Skills : Also extract skills based on the work experience.\n",
    "            Standardized Job Title: Identify the standardized job title for each work experience.\n",
    "            Standardized Job Title: Identify the standardized job title for each work experience.Skills based on work experience\n",
    "        \n",
    "3. Projects: Extract the details of the projects the candidate has worked on.\n",
    "                Predicted Skills : Also extract skills based on each project.\n",
    "        \n",
    "        \n",
    "4.Skills: Identify the technical and non-technical skills associated with each work experience and project.\n",
    "\n",
    "\n",
    "5.Career Trajectory: Identify the career progression of the candidate based on their work experience.\n",
    "\n",
    "Output them in the following format: \n",
    "Warning: if there is no data for any of the fields, leave it blank.\n",
    "\n",
    "        \"Education: \" and separate multiple entries with new line .\n",
    "        \n",
    "        \"Work: \" Organization Name, Location, Position, Start Date - End Date 'and separate multiple entries with a comma.\n",
    "            \"Job Title: \" Identify the  job title for each work experience. Clean and strip them off suffixes, prefixes and seniority.\n",
    "           \n",
    "            \" Predicted Skills : \" and separate multiple entries with a comma for each work experience.\n",
    "        Note: Separate each work experience with a new line.\n",
    "        Warning: Don't print this text - \"Organization Name, Location, Position, Start Date - End Date\" as it is in the output  .\n",
    "          \n",
    "        \n",
    "        \"Project Name, Start Date - End Date, Project Description \" and separate multiple entries with a comma and a new line for each project. ( \n",
    "            \" Predicted Skills : \" and separate multiple entries with a comma for each project.\n",
    "            Note:  Project Description should be in 30 to 40 words\n",
    "                \n",
    "        Note: Separate each project with a new line. \n",
    "        Warning: Don't print \"Project Name, Start Date - End Date, Project Description\"  as it is (text)  in the output .       \n",
    "        \n",
    "        \"Skills: \" Skills under the skills section.\n",
    "                    Classify them as technical and non-technical skills if possible.\n",
    "        \n",
    "        \"Career Trajectory: \" and separate multiple entries with a -> . Career Trajectory should be in ascending order with respect to date of joining.\n",
    "                eg1 : \"Data Analyst -> Data Scientist -> Senior Data Scientist\"\n",
    "                eg2 : \"School Name -> College Name -> University Name -> Job Title -> Job Title\"\n",
    "                \n",
    "Resume: {text}\n",
    "\n",
    "\\n{format_instructions}\\n\n",
    "\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:10:17.324005100Z",
     "start_time": "2024-03-02T05:10:17.312004900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Template "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "template = \"\"\" \n",
    "For the following text, extract the following information:\n",
    "\n",
    "Warning: Don't greet or write any introduction. Just start with the answer to the prompts. Do as per the instructions given in the prompt. If you don't know the answer, leave that part (keep blank) and move to the next part.\n",
    "\n",
    "1. Education: Extract the name of the all universities/colleges attended by the candidate with there CGPA.\n",
    "\n",
    "\n",
    "2. Work: Extract all organization names where he/she has worked along with the position held, and the duration of employment.\n",
    "            Predicted Skills : Also extract skills based on the work experience.\n",
    "            Standardized Job Title: Identify the standardized job title for each work experience.\n",
    "            Standardized Job Title: Identify the standardized job title for each work experience.Skills based on work experience\n",
    "        \n",
    "3. Projects: Extract the details of the projects the candidate has worked on.\n",
    "                Predicted Skills : Also extract skills based on each project.\n",
    "        \n",
    "        \n",
    "4.Skills: Identify the technical and non-technical skills associated with each work experience and project.\n",
    "\n",
    "\n",
    "5.Career Trajectory: Identify the career progression of the candidate based on their work experience.\n",
    "\n",
    "Output them in the following format: \n",
    "Warning: if there is no data for any of the fields, leave it blank.\n",
    "\n",
    "        \"Education: \" and separate multiple entries with new line .\n",
    "        \n",
    "        \"Work: \" Organization Name, Location, Position, Start Date - End Date 'and separate multiple entries with a comma.\n",
    "            \"Job Title: \" Identify the  job title for each work experience. Clean and strip them off suffixes, prefixes and seniority.\n",
    "           \n",
    "            \" Predicted Skills : \" and separate multiple entries with a comma for each work experience.\n",
    "        Note: Separate each work experience with a new line.\n",
    "        Warning: Don't print this text - \"Organization Name, Location, Position, Start Date - End Date\" as it is in the output  .\n",
    "          \n",
    "        \n",
    "        \"Project Name, Start Date - End Date, Project Description \" and separate multiple entries with a comma and a new line for each project. ( \n",
    "            \" Predicted Skills : \" and separate multiple entries with a comma for each project.\n",
    "            Note:  Project Description should be in 30 to 40 words\n",
    "                \n",
    "        Note: Separate each project with a new line. \n",
    "        Warning: Don't print \"Project Name, Start Date - End Date, Project Description\"  as it is (text)  in the output .       \n",
    "        \n",
    "        \"Skills: \" Skills under the skills section.\n",
    "                    Classify them as technical and non-technical skills if possible.\n",
    "        \n",
    "        \"Career Trajectory: \" and separate multiple entries with a -> . Career Trajectory should be in acsending order with respect to date of joining.\n",
    "                eg1 : \"Data Analyst -> Data Scientist -> Senior Data Scientist\"\n",
    "                eg2 : \"School Name -> College Name -> University Name -> Job Title -> Job Title\"\n",
    "                \n",
    "Resume: {text}\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T04:45:58.663910500Z",
     "start_time": "2024-03-02T04:45:58.646836800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extracting the details from the resume "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T04:46:20.932192600Z",
     "start_time": "2024-03-02T04:46:20.917188500Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_op_title(resume):\n",
    "    # parser = JsonOutputParser(pydantic_object=op_title_struture)\n",
    "    prompt = PromptTemplate(\n",
    "            template= template,\n",
    "            input_variables=[\"text\"],\n",
    "        )\n",
    "    chain = prompt | chat_llm \n",
    "\n",
    "    result = chain.invoke({\"text\": resume})\n",
    "\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "res = get_op_title(resume2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T04:46:28.557545700Z",
     "start_time": "2024-03-02T04:46:21.647813400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "str"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T04:46:31.063792Z",
     "start_time": "2024-03-02T04:46:31.023795Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education: \n",
      "New York University, Center For Data Science (GPA: 3.91/4.0)\n",
      "Institute of Technology, Nirma University (GPA: 3.8/4.0)\n",
      "\n",
      "Work: \n",
      "Revelio Labs, New York, Data Scientist, Jul 2021 - Present\n",
      "Coursera, Mountain View, CA, Marketing Data Scientist Intern, Oct 2020 - Dec 2020\n",
      "Wellness Space, India, Data Analyst | Technical Consultant, Jan 2019 - Jun 2019\n",
      "\n",
      "Job Title: \n",
      "Data Scientist\n",
      "Marketing Data Scientist Intern\n",
      "Data Analyst | Technical Consultant\n",
      "\n",
      "Predicted Skills: \n",
      "Graph ML algorithms, Bayesian Additive Regression Trees, Data structuring, SVM, LSTM models, Anomaly detection\n",
      "\n",
      "Projects: \n",
      "Impact of Career Development Services in Career Outcomes, Sep 2020 - Dec 2020, Quantified impact of NYU Wasserman Center for Career Development on students’ actual career outcomes\n",
      "Evaluating Summarization Tasks Using Sentence-BERT, Mar 2020 - May 2020, Devised a novel metric for evaluation of Summarization Tasks\n",
      "Diabetic Retinopathy Detection Using Deep Learning, Jan 2018 - Dec 2018, Identified key factors for detection and deployed CNN models\n",
      "Job Recommendation Engine, Oct 2019 - Dec 2019, Developed a Recommendation Engine using NLTK and Cosine Similarity\n",
      "Optimal Location Prediction for Emergency Stations, Jul 2018 - Jan 2019, Formulated ML/DL Models for Travel Time Estimation\n",
      "\n",
      "Predicted Skills: \n",
      "Logistic Regression, Decision Trees, Sentence embeddings, CNN models, Data Augmentation, XGBoost, K-Medoids\n",
      "\n",
      "Skills: \n",
      "Technical Skills: Scikit-Learn, Tensorflow, Keras, PyTorch, Scipy, PySpark, NumPy, Pandas, Matplotlib, Plotly, GCP, AWS, Python, SQL, R, Java, C++, JavaScript, Hadoop, Spark, Hive\n",
      "\n",
      "Career Trajectory: \n",
      "Data Analyst -> Marketing Data Scientist Intern -> Data Scientist\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T04:46:31.658530400Z",
     "start_time": "2024-03-02T04:46:31.647529500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extracting the details from the resume and converting it into json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One field "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class ResumeStructure(BaseModel):\n",
    "        education : List[str] = Field(description=\"List of all universities/colleges attended by the candidate with there CGPA.\")\n",
    "def get_op_edu(resume):\n",
    "    parser = JsonOutputParser(pydantic_object=ResumeStructure)\n",
    "    prompt = PromptTemplate(\n",
    "            template= template_i,\n",
    "            input_variables=[\"text\"],\n",
    "         partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "        )\n",
    "    chain = prompt | chat_llm | parser\n",
    "\n",
    "    result = chain.invoke({\"text\": resume})\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T04:47:20.747446200Z",
     "start_time": "2024-03-02T04:47:20.740446700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "edu = get_op_edu(resume2) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T13:36:00.761247800Z",
     "start_time": "2024-03-01T13:35:58.951521600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "{'education': ['New York University, Center For Data Science (GPA: 3.91/4.0) New York, NY',\n  'Institute of Technology, Nirma University (GPA: 3.8/4.0) India']}"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T13:36:03.827608100Z",
     "start_time": "2024-03-01T13:36:03.785678500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "dict"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(edu)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T13:36:32.252750400Z",
     "start_time": "2024-03-01T13:36:32.231542200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All fields "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "chat_llm_json = ChatOpenAI(model='gpt-3.5-turbo',temperature=0.6)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:16:44.689966Z",
     "start_time": "2024-03-02T05:16:44.664967Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class ResumeStructureF(BaseModel):\n",
    "    education : List[Dict[str, str]] = Field(description=\"List of dictionaries containing 'university' and 'CGPA'\")\n",
    "    work : List[Dict[str, Union[str, List[str]]]] = Field(description=\"List of dictionaries containing 'organization', 'location', 'position', 'duration', 'job_title', and 'predicted_skills'\")\n",
    "    projects : List[Dict[str, Union[str, List[str]]]] = Field(description=\"List of dictionaries containing 'project_name', 'start_date', 'end_date', 'description', and 'predicted_skills'\")\n",
    "    skills : Dict[str, List[str]] = Field(description=\"Dictionary containing 'technical' and 'non_technical' skills\")\n",
    "    career_trajectory : str = Field(description=\"String representing the career progression of the candidate\")\n",
    "\n",
    "\n",
    "\n",
    "def get_op_edu(resume):\n",
    "    parser = JsonOutputParser(pydantic_object=ResumeStructureF)\n",
    "    prompt = PromptTemplate(\n",
    "            template= template_i,\n",
    "            input_variables=[\"text\"],\n",
    "         partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "        )\n",
    "    chain = prompt | chat_llm_json | parser\n",
    "\n",
    "    result = chain.invoke({\"text\": resume})\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:16:45.687414Z",
     "start_time": "2024-03-02T05:16:45.681413600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "out = get_op_edu(resume2) \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:16:59.653889Z",
     "start_time": "2024-03-02T05:16:46.161946400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "{'education': [{'university': 'New York University, Center For Data Science',\n   'CGPA': '3.91/4.0'},\n  {'university': 'Institute of Technology, Nirma University',\n   'CGPA': '3.8/4.0'}],\n 'work': [{'organization': 'Revelio Labs',\n   'location': 'New York, New York',\n   'position': 'Data Scientist',\n   'duration': 'Jul 2021 - Present',\n   'job_title': 'Data Scientist',\n   'predicted_skills': ['Graph ML algorithms',\n    'Bayesian Additive Regression Trees',\n    'Data structuring']},\n  {'organization': 'Coursera',\n   'location': 'Mountain View, CA',\n   'position': 'Marketing Data Scientist Intern: ML Group',\n   'duration': 'Oct 2020 - Dec 2020',\n   'job_title': 'Marketing Data Scientist Intern',\n   'predicted_skills': ['Health Dashboard development',\n    'Bayesian approach',\n    'Model revision']},\n  {'organization': 'Wellness Space',\n   'location': 'India',\n   'position': 'Data Analyst | Technical Consultant',\n   'duration': 'Jan 2019 - Jun 2019',\n   'job_title': 'Data Analyst',\n   'predicted_skills': ['SVM and LSTM models',\n    'Anomaly detection',\n    'Application deployment']}],\n 'projects': [{'project_name': 'Impact of Career Development Services in Career Outcomes',\n   'start_date': 'Sep 2020',\n   'end_date': 'Dec 2020',\n   'description': 'Quantified impact of NYU Wasserman Center for Career Development on students’ career outcomes and designed a framework for career coaching activities.',\n   'predicted_skills': ['Logistic Regression', 'Decision Trees']},\n  {'project_name': 'Evaluating Summarization Tasks Using Sentence-BERT',\n   'start_date': 'Mar 2020',\n   'end_date': 'May 2020',\n   'description': 'Devised a metric using SentenceBERT embeddings for Summarization Tasks evaluation and validated its correlation with human evaluation.',\n   'predicted_skills': ['Sentence embeddings', 'Evaluation metrics']},\n  {'project_name': 'Diabetic Retinopathy Detection Using Deep Learning',\n   'start_date': 'Jan 2018',\n   'end_date': 'Dec 2018',\n   'description': 'Identified key factors for diabetic retinopathy detection, deployed CNN models, and performed data augmentation and segmentation.',\n   'predicted_skills': ['CNN models',\n    'Data augmentation',\n    'Image segmentation']},\n  {'project_name': 'Job Recommendation Engine',\n   'start_date': 'Oct 2019',\n   'end_date': 'Dec 2019',\n   'description': 'Developed a Recommendation Engine using NLTK for keyword extraction and cosine similarity computation for job recommendations.',\n   'predicted_skills': ['NLTK',\n    'Cosine Similarity',\n    'Recommendation Systems']},\n  {'project_name': 'Optimal Location Prediction for Emergency Stations',\n   'start_date': 'Jul 2018',\n   'end_date': 'Jan 2019',\n   'description': 'Formulated ML/DL models for optimal emergency station location prediction and reduced turnaround time.',\n   'predicted_skills': ['ML/DL Models',\n    'Travel Time Estimation',\n    'K-Medoids']}],\n 'skills': {'technical': ['Scikit-Learn',\n   'Tensorflow',\n   'Keras',\n   'PyTorch',\n   'Scipy',\n   'PySpark',\n   'NumPy',\n   'Pandas',\n   'Matplotlib',\n   'Plotly',\n   'GCP',\n   'AWS',\n   'SQL',\n   'Java',\n   'C++',\n   'JavaScript',\n   'Hadoop',\n   'Spark',\n   'Hive'],\n  'non_technical': []},\n 'career_trajectory': 'Data Analyst -> Marketing Data Scientist Intern -> Data Scientist'}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:17:00.844543800Z",
     "start_time": "2024-03-02T05:17:00.823467100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "dict"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:18:30.395404300Z",
     "start_time": "2024-03-02T05:18:30.376949400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "{'education': [{'university': 'New York University, Center For Data Science',\n   'CGPA': '3.91/4.0'},\n  {'university': 'Institute of Technology, Nirma University',\n   'CGPA': '3.8/4.0'}],\n 'work': [{'organization': 'Revelio Labs',\n   'location': 'New York, New York',\n   'position': 'Data Scientist',\n   'duration': 'Jul 2021 - Present',\n   'job_title': 'Data Scientist',\n   'predicted_skills': ['Graph ML algorithms',\n    'Bayesian Additive Regression Trees',\n    'Data structuring']},\n  {'organization': 'Coursera',\n   'location': 'Mountain View, CA',\n   'position': 'Marketing Data Scientist Intern: ML Group',\n   'duration': 'Oct 2020 - Dec 2020',\n   'job_title': 'Marketing Data Scientist Intern',\n   'predicted_skills': ['Health Dashboard development',\n    'Bayesian approach',\n    'Model revision']},\n  {'organization': 'Wellness Space',\n   'location': 'India',\n   'position': 'Data Analyst | Technical Consultant',\n   'duration': 'Jan 2019 - Jun 2019',\n   'job_title': 'Data Analyst',\n   'predicted_skills': ['SVM and LSTM models',\n    'Anomaly detection',\n    'Application deployment']}],\n 'projects': [{'project_name': 'Impact of Career Development Services in Career Outcomes',\n   'start_date': 'Sep 2020',\n   'end_date': 'Dec 2020',\n   'description': 'Quantified impact of NYU Wasserman Center for Career Development on students’ career outcomes and designed a framework for career coaching activities.',\n   'predicted_skills': ['Logistic Regression', 'Decision Trees']},\n  {'project_name': 'Evaluating Summarization Tasks Using Sentence-BERT',\n   'start_date': 'Mar 2020',\n   'end_date': 'May 2020',\n   'description': 'Devised a metric using SentenceBERT embeddings for Summarization Tasks evaluation and validated its correlation with human evaluation.',\n   'predicted_skills': ['Sentence embeddings', 'Evaluation metrics']},\n  {'project_name': 'Diabetic Retinopathy Detection Using Deep Learning',\n   'start_date': 'Jan 2018',\n   'end_date': 'Dec 2018',\n   'description': 'Identified key factors for diabetic retinopathy detection, deployed CNN models, and performed data augmentation and segmentation.',\n   'predicted_skills': ['CNN models',\n    'Data augmentation',\n    'Image segmentation']},\n  {'project_name': 'Job Recommendation Engine',\n   'start_date': 'Oct 2019',\n   'end_date': 'Dec 2019',\n   'description': 'Developed a Recommendation Engine using NLTK for keyword extraction and cosine similarity computation for job recommendations.',\n   'predicted_skills': ['NLTK',\n    'Cosine Similarity',\n    'Recommendation Systems']},\n  {'project_name': 'Optimal Location Prediction for Emergency Stations',\n   'start_date': 'Jul 2018',\n   'end_date': 'Jan 2019',\n   'description': 'Formulated ML/DL models for optimal emergency station location prediction and reduced turnaround time.',\n   'predicted_skills': ['ML/DL Models',\n    'Travel Time Estimation',\n    'K-Medoids']}],\n 'skills': {'technical': ['Scikit-Learn',\n   'Tensorflow',\n   'Keras',\n   'PyTorch',\n   'Scipy',\n   'PySpark',\n   'NumPy',\n   'Pandas',\n   'Matplotlib',\n   'Plotly',\n   'GCP',\n   'AWS',\n   'SQL',\n   'Java',\n   'C++',\n   'JavaScript',\n   'Hadoop',\n   'Spark',\n   'Hive'],\n  'non_technical': []},\n 'career_trajectory': 'Data Analyst -> Marketing Data Scientist Intern -> Data Scientist'}"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:18:31.845430900Z",
     "start_time": "2024-03-02T05:18:31.838412400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exporting the details into json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# export edu to json\n",
    "with open('output_schema_json.json', 'w') as f:\n",
    "    json_data = json.dumps(out, indent=4)\n",
    "    f.write(json_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:11:21.957669400Z",
     "start_time": "2024-03-02T05:11:21.944666900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.JSON object>",
      "application/json": {
       "education": [
        {
         "university": "New York University, Center For Data Science",
         "CGPA": "3.91/4.0"
        },
        {
         "university": "Institute of Technology, Nirma University",
         "CGPA": "3.8/4.0"
        }
       ],
       "work": [
        {
         "organization": "Revelio Labs",
         "location": "New York, New York",
         "position": "Data Scientist",
         "duration": "Jul 2021 - Present",
         "standardized_job_title": "Data Scientist",
         "predicted_skills": [
          "Graph ML algorithms",
          "Node2Vec",
          "Bayesian Additive Regression Trees",
          "Data structuring"
         ]
        },
        {
         "organization": "Coursera",
         "location": "Mountain View, CA",
         "position": "Marketing Data Scientist Intern: ML Group",
         "duration": "Oct 2020 - Dec 2020",
         "standardized_job_title": "Marketing Data Scientist Intern",
         "predicted_skills": [
          "Health Dashboard creation",
          "A/B/C tests",
          "Bayesian approach",
          "Degree Forecasting"
         ]
        },
        {
         "organization": "Wellness Space",
         "location": "India",
         "position": "Data Analyst | Technical Consultant",
         "duration": "Jan 2019 - Jun 2019",
         "standardized_job_title": "Data Analyst",
         "predicted_skills": [
          "SVM models",
          "LSTM models",
          "Anomaly detection",
          "ECG signal analysis"
         ]
        }
       ],
       "projects": [
        {
         "project_name": "Impact of Career Development Services in Career Outcomes",
         "start_date": "Sep 2020",
         "end_date": "Dec 2020",
         "description": "Quantified impact of NYU Wasserman Center for Career Development on students’ actual career outcomes",
         "predicted_skills": [
          "Logistic Regression",
          "Decision Trees",
          "Career coaching"
         ]
        },
        {
         "project_name": "Evaluating Summarization Tasks Using Sentence-BERT",
         "start_date": "Mar 2020",
         "end_date": "May 2020",
         "description": "Devised a novel metric by employing sentence embeddings from SentenceBERT for evaluation of Summarization Tasks",
         "predicted_skills": [
          "Sentence embeddings",
          "Summarization evaluation",
          "Dataset analysis"
         ]
        },
        {
         "project_name": "Diabetic Retinopathy Detection Using Deep Learning",
         "start_date": "Jan 2018",
         "end_date": "Dec 2018",
         "description": "Identified key factors for detection of Diabetic Retinopathy and deployed CNN models",
         "predicted_skills": [
          "CNN models",
          "Data Augmentation",
          "Image Segmentation"
         ]
        },
        {
         "project_name": "Job Recommendation Engine",
         "start_date": "Oct 2019",
         "end_date": "Dec 2019",
         "description": "Developed a Recommendation Engine by computing Cosine Similarity and utilized Hit Ratio for evaluating performance",
         "predicted_skills": [
          "Recommendation Engine",
          "Cosine Similarity",
          "NLTK"
         ]
        },
        {
         "project_name": "Optimal Location Prediction for Emergency Stations",
         "start_date": "Jul 2018",
         "end_date": "Jan 2019",
         "description": "Formulated ML/DL Models to identify best suitable model for Travel Time Estimation",
         "predicted_skills": [
          "ML/DL Models",
          "Travel Time Estimation",
          "K-Medoids"
         ]
        }
       ],
       "skills": {
        "technical": [
         "Scikit-Learn",
         "Tensorflow",
         "Keras",
         "PyTorch",
         "Scipy",
         "PySpark",
         "NumPy",
         "Pandas",
         "Matplotlib",
         "Plotly",
         "GCP",
         "AWS",
         "Python",
         "SQL",
         "R",
         "Java",
         "C++",
         "JavaScript",
         "Hadoop",
         "Spark",
         "Hive"
        ],
        "non_technical": []
       },
       "career_trajectory": "Data Analyst -> Marketing Data Scientist Intern -> Data Scientist"
      }
     },
     "execution_count": 107,
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import JSON\n",
    "JSON(edu, expanded=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T14:55:56.145943600Z",
     "start_time": "2024-03-01T14:55:56.132939800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "{'organization': 'Revelio Labs',\n 'location': 'New York, New York',\n 'position': 'Data Scientist',\n 'duration': 'Jul 2021 - Present',\n 'job_title': 'Data Scientist',\n 'predicted_skills': ['Graph ML algorithms',\n  'Bayesian Additive Regression Trees',\n  'Data structuring']}"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['work'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:20:09.753089300Z",
     "start_time": "2024-03-02T05:20:09.726089300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "for i in out['work']:\n",
    "    key = i['organization']\n",
    "    value = i['job_title']\n",
    "    \n",
    "    # make a new dictionary with the key and value\n",
    "    new_dict[key] = value\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:23:01.687081500Z",
     "start_time": "2024-03-02T05:23:01.670073300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "{'organization': 'Revelio Labs',\n 'location': 'New York, New York',\n 'position': 'Data Scientist',\n 'duration': 'Jul 2021 - Present',\n 'job_title': 'Data Scientist',\n 'predicted_skills': ['Graph ML algorithms',\n  'Bayesian Additive Regression Trees',\n  'Data structuring']}"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['work'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:23:02.886161700Z",
     "start_time": "2024-03-02T05:23:02.868177200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Revelio Labs': 'Data Scientist',\n 'Coursera': 'Marketing Data Scientist Intern',\n 'Wellness Space': 'Data Analyst'}"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:23:03.109590300Z",
     "start_time": "2024-03-02T05:23:03.100590700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:41:34.380320300Z",
     "start_time": "2024-03-02T05:41:34.342322500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=r\"C:\\Users\\jaini\\Downloads\\2019_Occupations.csv\" ,encoding=\"utf-8\", csv_args={\n",
    "                'delimiter': ','})\n",
    "\n",
    "data_onet = loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:41:36.555014400Z",
     "start_time": "2024-03-02T05:41:36.536019400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(data_onet, embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:44:09.206058400Z",
     "start_time": "2024-03-02T05:43:58.533279200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:46:21.919889400Z",
     "start_time": "2024-03-02T05:46:21.907892900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=chat_llm,\n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=vectorstore.as_retriever(), \n",
    "                                  return_source_documents=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:46:23.715052800Z",
     "start_time": "2024-03-02T05:46:23.701049600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "llm = ChatOpenAI(temperature=0.0,model_name='gpt-3.5-turbo'),\n",
    "retriever=vectorstore.as_retriever())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:44:10.878567400Z",
     "start_time": "2024-03-02T05:44:10.842567Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "query = f\"\"\" Map the give job title to the ONET code and title for give dictionary of job titles. \n",
    "\n",
    "\n",
    "\n",
    "Dictionary : {new_dict} \n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:44:12.891842300Z",
     "start_time": "2024-03-02T05:44:12.880851800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-IwehcL7gYNc8Zv6OtpG9DzBH on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRateLimitError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[77], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m llm_response \u001B[38;5;241m=\u001B[39m \u001B[43mqa_chain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    143\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    144\u001B[0m     emit_warning()\n\u001B[1;32m--> 145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m wrapped(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\base.py:378\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001B[0m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Execute the chain.\u001B[39;00m\n\u001B[0;32m    347\u001B[0m \n\u001B[0;32m    348\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    369\u001B[0m \u001B[38;5;124;03m        `Chain.output_keys`.\u001B[39;00m\n\u001B[0;32m    370\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    371\u001B[0m config \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    372\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m: callbacks,\n\u001B[0;32m    373\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m: tags,\n\u001B[0;32m    374\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: metadata,\n\u001B[0;32m    375\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: run_name,\n\u001B[0;32m    376\u001B[0m }\n\u001B[1;32m--> 378\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    380\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mRunnableConfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    381\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[43m    \u001B[49m\u001B[43minclude_run_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_run_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\base.py:163\u001B[0m, in \u001B[0;36mChain.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    162\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[1;32m--> 163\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    164\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m include_run_info:\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\base.py:153\u001B[0m, in \u001B[0;36mChain.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_inputs(inputs)\n\u001B[0;32m    152\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 153\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    154\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[0;32m    155\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[0;32m    156\u001B[0m     )\n\u001B[0;32m    158\u001B[0m     final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[0;32m    159\u001B[0m         inputs, outputs, return_only_outputs\n\u001B[0;32m    160\u001B[0m     )\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:144\u001B[0m, in \u001B[0;36mBaseRetrievalQA._call\u001B[1;34m(self, inputs, run_manager)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    143\u001B[0m     docs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_docs(question)  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 144\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcombine_documents_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    145\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_documents\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquestion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquestion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_run_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_source_documents:\n\u001B[0;32m    149\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key: answer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource_documents\u001B[39m\u001B[38;5;124m\"\u001B[39m: docs}\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    143\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    144\u001B[0m     emit_warning()\n\u001B[1;32m--> 145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m wrapped(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\base.py:550\u001B[0m, in \u001B[0;36mChain.run\u001B[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001B[0m\n\u001B[0;32m    545\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(args[\u001B[38;5;241m0\u001B[39m], callbacks\u001B[38;5;241m=\u001B[39mcallbacks, tags\u001B[38;5;241m=\u001B[39mtags, metadata\u001B[38;5;241m=\u001B[39mmetadata)[\n\u001B[0;32m    546\u001B[0m         _output_key\n\u001B[0;32m    547\u001B[0m     ]\n\u001B[0;32m    549\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[1;32m--> 550\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m[\n\u001B[0;32m    551\u001B[0m         _output_key\n\u001B[0;32m    552\u001B[0m     ]\n\u001B[0;32m    554\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[0;32m    555\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    556\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    557\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m but none were provided.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    558\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    143\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    144\u001B[0m     emit_warning()\n\u001B[1;32m--> 145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m wrapped(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\base.py:378\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001B[0m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Execute the chain.\u001B[39;00m\n\u001B[0;32m    347\u001B[0m \n\u001B[0;32m    348\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    369\u001B[0m \u001B[38;5;124;03m        `Chain.output_keys`.\u001B[39;00m\n\u001B[0;32m    370\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    371\u001B[0m config \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    372\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m: callbacks,\n\u001B[0;32m    373\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m: tags,\n\u001B[0;32m    374\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: metadata,\n\u001B[0;32m    375\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: run_name,\n\u001B[0;32m    376\u001B[0m }\n\u001B[1;32m--> 378\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    380\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mRunnableConfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    381\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[43m    \u001B[49m\u001B[43minclude_run_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_run_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\base.py:163\u001B[0m, in \u001B[0;36mChain.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    162\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[1;32m--> 163\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    164\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m include_run_info:\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\base.py:153\u001B[0m, in \u001B[0;36mChain.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_inputs(inputs)\n\u001B[0;32m    152\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 153\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    154\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[0;32m    155\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[0;32m    156\u001B[0m     )\n\u001B[0;32m    158\u001B[0m     final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[0;32m    159\u001B[0m         inputs, outputs, return_only_outputs\n\u001B[0;32m    160\u001B[0m     )\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:137\u001B[0m, in \u001B[0;36mBaseCombineDocumentsChain._call\u001B[1;34m(self, inputs, run_manager)\u001B[0m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001B[39;00m\n\u001B[0;32m    136\u001B[0m other_keys \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_key}\n\u001B[1;32m--> 137\u001B[0m output, extra_return_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcombine_docs(\n\u001B[0;32m    138\u001B[0m     docs, callbacks\u001B[38;5;241m=\u001B[39m_run_manager\u001B[38;5;241m.\u001B[39mget_child(), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mother_keys\n\u001B[0;32m    139\u001B[0m )\n\u001B[0;32m    140\u001B[0m extra_return_dict[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key] \u001B[38;5;241m=\u001B[39m output\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m extra_return_dict\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:244\u001B[0m, in \u001B[0;36mStuffDocumentsChain.combine_docs\u001B[1;34m(self, docs, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    242\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_inputs(docs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    243\u001B[0m \u001B[38;5;66;03m# Call predict on the LLM.\u001B[39;00m\n\u001B[1;32m--> 244\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm_chain\u001B[38;5;241m.\u001B[39mpredict(callbacks\u001B[38;5;241m=\u001B[39mcallbacks, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs), {}\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\llm.py:293\u001B[0m, in \u001B[0;36mLLMChain.predict\u001B[1;34m(self, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, callbacks: Callbacks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m    279\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001B[39;00m\n\u001B[0;32m    280\u001B[0m \n\u001B[0;32m    281\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    291\u001B[0m \u001B[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001B[39;00m\n\u001B[0;32m    292\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 293\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key]\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    143\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    144\u001B[0m     emit_warning()\n\u001B[1;32m--> 145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m wrapped(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\base.py:378\u001B[0m, in \u001B[0;36mChain.__call__\u001B[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001B[0m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Execute the chain.\u001B[39;00m\n\u001B[0;32m    347\u001B[0m \n\u001B[0;32m    348\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    369\u001B[0m \u001B[38;5;124;03m        `Chain.output_keys`.\u001B[39;00m\n\u001B[0;32m    370\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    371\u001B[0m config \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    372\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m: callbacks,\n\u001B[0;32m    373\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m: tags,\n\u001B[0;32m    374\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: metadata,\n\u001B[0;32m    375\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: run_name,\n\u001B[0;32m    376\u001B[0m }\n\u001B[1;32m--> 378\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    380\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[43mRunnableConfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43mk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    381\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_only_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[43m    \u001B[49m\u001B[43minclude_run_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_run_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\base.py:163\u001B[0m, in \u001B[0;36mChain.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    162\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[1;32m--> 163\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    164\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m include_run_info:\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\base.py:153\u001B[0m, in \u001B[0;36mChain.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_inputs(inputs)\n\u001B[0;32m    152\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 153\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    154\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[0;32m    155\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[0;32m    156\u001B[0m     )\n\u001B[0;32m    158\u001B[0m     final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[0;32m    159\u001B[0m         inputs, outputs, return_only_outputs\n\u001B[0;32m    160\u001B[0m     )\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\llm.py:103\u001B[0m, in \u001B[0;36mLLMChain._call\u001B[1;34m(self, inputs, run_manager)\u001B[0m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call\u001B[39m(\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    100\u001B[0m     inputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[0;32m    101\u001B[0m     run_manager: Optional[CallbackManagerForChainRun] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    102\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m--> 103\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_outputs(response)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain\\chains\\llm.py:115\u001B[0m, in \u001B[0;36mLLMChain.generate\u001B[1;34m(self, input_list, run_manager)\u001B[0m\n\u001B[0;32m    113\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m run_manager\u001B[38;5;241m.\u001B[39mget_child() \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm, BaseLanguageModel):\n\u001B[1;32m--> 115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm\u001B[38;5;241m.\u001B[39mgenerate_prompt(\n\u001B[0;32m    116\u001B[0m         prompts,\n\u001B[0;32m    117\u001B[0m         stop,\n\u001B[0;32m    118\u001B[0m         callbacks\u001B[38;5;241m=\u001B[39mcallbacks,\n\u001B[0;32m    119\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm_kwargs,\n\u001B[0;32m    120\u001B[0m     )\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    122\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm\u001B[38;5;241m.\u001B[39mbind(stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm_kwargs)\u001B[38;5;241m.\u001B[39mbatch(\n\u001B[0;32m    123\u001B[0m         cast(List, prompts), {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m: callbacks}\n\u001B[0;32m    124\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:544\u001B[0m, in \u001B[0;36mBaseChatModel.generate_prompt\u001B[1;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    536\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[0;32m    537\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    538\u001B[0m     prompts: List[PromptValue],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    541\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    542\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[0;32m    543\u001B[0m     prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[1;32m--> 544\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate(prompt_messages, stop\u001B[38;5;241m=\u001B[39mstop, callbacks\u001B[38;5;241m=\u001B[39mcallbacks, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:408\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001B[0m\n\u001B[0;32m    406\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n\u001B[0;32m    407\u001B[0m             run_managers[i]\u001B[38;5;241m.\u001B[39mon_llm_error(e, response\u001B[38;5;241m=\u001B[39mLLMResult(generations\u001B[38;5;241m=\u001B[39m[]))\n\u001B[1;32m--> 408\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    409\u001B[0m flattened_outputs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    410\u001B[0m     LLMResult(generations\u001B[38;5;241m=\u001B[39m[res\u001B[38;5;241m.\u001B[39mgenerations], llm_output\u001B[38;5;241m=\u001B[39mres\u001B[38;5;241m.\u001B[39mllm_output)\n\u001B[0;32m    411\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results\n\u001B[0;32m    412\u001B[0m ]\n\u001B[0;32m    413\u001B[0m llm_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_combine_llm_outputs([res\u001B[38;5;241m.\u001B[39mllm_output \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results])\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:398\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001B[0m\n\u001B[0;32m    395\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages):\n\u001B[0;32m    396\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    397\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m--> 398\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_with_cache(\n\u001B[0;32m    399\u001B[0m                 m,\n\u001B[0;32m    400\u001B[0m                 stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[0;32m    401\u001B[0m                 run_manager\u001B[38;5;241m=\u001B[39mrun_managers[i] \u001B[38;5;28;01mif\u001B[39;00m run_managers \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    402\u001B[0m                 \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    403\u001B[0m             )\n\u001B[0;32m    404\u001B[0m         )\n\u001B[0;32m    405\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    406\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:577\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[1;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[0;32m    573\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    574\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    575\u001B[0m     )\n\u001B[0;32m    576\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported:\n\u001B[1;32m--> 577\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(\n\u001B[0;32m    578\u001B[0m         messages, stop\u001B[38;5;241m=\u001B[39mstop, run_manager\u001B[38;5;241m=\u001B[39mrun_manager, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    579\u001B[0m     )\n\u001B[0;32m    580\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    581\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain_community\\chat_models\\openai.py:441\u001B[0m, in \u001B[0;36mChatOpenAI._generate\u001B[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001B[0m\n\u001B[0;32m    435\u001B[0m message_dicts, params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_message_dicts(messages, stop)\n\u001B[0;32m    436\u001B[0m params \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    437\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[0;32m    438\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m: stream} \u001B[38;5;28;01mif\u001B[39;00m stream \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}),\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    440\u001B[0m }\n\u001B[1;32m--> 441\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompletion_with_retry(\n\u001B[0;32m    442\u001B[0m     messages\u001B[38;5;241m=\u001B[39mmessage_dicts, run_manager\u001B[38;5;241m=\u001B[39mrun_manager, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\n\u001B[0;32m    443\u001B[0m )\n\u001B[0;32m    444\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_chat_result(response)\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\langchain_community\\chat_models\\openai.py:356\u001B[0m, in \u001B[0;36mChatOpenAI.completion_with_retry\u001B[1;34m(self, run_manager, **kwargs)\u001B[0m\n\u001B[0;32m    354\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001B[39;00m\n\u001B[0;32m    355\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_openai_v1():\n\u001B[1;32m--> 356\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    358\u001B[0m retry_decorator \u001B[38;5;241m=\u001B[39m _create_retry_decorator(\u001B[38;5;28mself\u001B[39m, run_manager\u001B[38;5;241m=\u001B[39mrun_manager)\n\u001B[0;32m    360\u001B[0m \u001B[38;5;129m@retry_decorator\u001B[39m\n\u001B[0;32m    361\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_completion_with_retry\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\openai\\_utils\\_utils.py:275\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    273\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    274\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[1;32m--> 275\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\openai\\resources\\chat\\completions.py:663\u001B[0m, in \u001B[0;36mCompletions.create\u001B[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[0;32m    611\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    612\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[0;32m    613\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    661\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[0;32m    662\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[1;32m--> 663\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    664\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    665\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    666\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m    667\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    668\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    669\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrequency_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    670\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunction_call\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    671\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunctions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    672\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogit_bias\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    673\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    674\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    675\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    676\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpresence_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    677\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    678\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    679\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    680\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    681\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    682\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    683\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    684\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_logprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    685\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    686\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    687\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    688\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    689\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    690\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    691\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m    692\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    693\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    694\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    695\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    696\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\openai\\_base_client.py:1200\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[0;32m   1187\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1188\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1195\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1196\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m   1197\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[0;32m   1198\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[0;32m   1199\u001B[0m     )\n\u001B[1;32m-> 1200\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\openai\\_base_client.py:889\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    880\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[0;32m    881\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    882\u001B[0m     cast_to: Type[ResponseT],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    887\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    888\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m--> 889\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    890\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    891\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    892\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    893\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    894\u001B[0m \u001B[43m        \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    895\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\openai\\_base_client.py:965\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    963\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[0;32m    964\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[1;32m--> 965\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    966\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    967\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    968\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    969\u001B[0m \u001B[43m        \u001B[49m\u001B[43merr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    970\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    971\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    974\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[0;32m    975\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[0;32m    976\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\openai\\_base_client.py:1013\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1009\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[0;32m   1010\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[0;32m   1011\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[1;32m-> 1013\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1014\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1015\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1016\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1017\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1018\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1019\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\openai\\_base_client.py:965\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    963\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[0;32m    964\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[1;32m--> 965\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    966\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    967\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    968\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    969\u001B[0m \u001B[43m        \u001B[49m\u001B[43merr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    970\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    971\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    974\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[0;32m    975\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[0;32m    976\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\openai\\_base_client.py:1013\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1009\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[0;32m   1010\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[0;32m   1011\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[1;32m-> 1013\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1014\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1015\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1016\u001B[0m \u001B[43m    \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1017\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1018\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1019\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\mined_resume\\venv\\lib\\site-packages\\openai\\_base_client.py:980\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    977\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m    979\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 980\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    982\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[0;32m    983\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[0;32m    984\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    987\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[0;32m    988\u001B[0m )\n",
      "\u001B[1;31mRateLimitError\u001B[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-IwehcL7gYNc8Zv6OtpG9DzBH on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "llm_response = qa_chain(query)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T07:03:26.677052300Z",
     "start_time": "2024-03-02T07:03:20.827308700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "{'query': \" Map the give job title to the ONET code and title for give dictionary of job titles. \\n\\n\\n\\nDictionary : {'Revelio Labs': 'Data Scientist', 'Coursera': 'Marketing Data Scientist Intern', 'Wellness Space': 'Data Analyst'} \\n\\n\",\n 'result': \"{'Revelio Labs': ('15-2051.00', 'Data Scientists'), 'Coursera': ('15-2051.00', 'Data Scientists'), 'Wellness Space': ('15-1251.00', 'Data Analyst')}\",\n 'source_documents': [Document(page_content='O*NET-SOC 2019 Code: 15-2051.00\\nO*NET-SOC 2019 Title: Data Scientists\\nO*NET-SOC 2019 Description: Develop and implement a set of techniques or analytics applications to transform raw data into meaningful information using data-oriented programming languages and visualization software. Apply data mining, data modeling, natural language processing, and machine learning to extract and analyze information from large structured and unstructured datasets. Visualize, interpret, and report data findings. May create dynamic data reports.', metadata={'source': 'C:\\\\Users\\\\jaini\\\\Downloads\\\\2019_Occupations.csv', 'row': 142}),\n  Document(page_content='O*NET-SOC 2019 Code: 33-9021.00\\nO*NET-SOC 2019 Title: Private Detectives and Investigators\\nO*NET-SOC 2019 Description: Gather, analyze, compile, and report information regarding individuals or organizations to clients, or detect occurrences of unlawful acts or infractions of rules in private establishment.', metadata={'source': 'C:\\\\Users\\\\jaini\\\\Downloads\\\\2019_Occupations.csv', 'row': 546}),\n  Document(page_content='O*NET-SOC 2019 Code: 29-1031.00\\nO*NET-SOC 2019 Title: Dietitians and Nutritionists\\nO*NET-SOC 2019 Description: Plan and conduct food service or nutritional programs to assist in the promotion of health and control of disease. May supervise activities of a department providing quantity food services, counsel individuals, or conduct nutritional research.', metadata={'source': 'C:\\\\Users\\\\jaini\\\\Downloads\\\\2019_Occupations.csv', 'row': 417}),\n  Document(page_content='O*NET-SOC 2019 Code: 33-3021.00\\nO*NET-SOC 2019 Title: Detectives and Criminal Investigators\\nO*NET-SOC 2019 Description: Conduct investigations related to suspected violations of federal, state, or local laws to prevent or solve crimes.', metadata={'source': 'C:\\\\Users\\\\jaini\\\\Downloads\\\\2019_Occupations.csv', 'row': 537})]}"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:48:00.629253200Z",
     "start_time": "2024-03-02T05:48:00.600732800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "\"{'Revelio Labs': ('15-2051.00', 'Data Scientists'), 'Coursera': ('15-2051.00', 'Data Scientists'), 'Wellness Space': ('15-1251.00', 'Data Analyst')}\""
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response['result']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T05:50:11.921359600Z",
     "start_time": "2024-03-02T05:50:11.906359400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from onet import onet_job_title_to_onet_code\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = onet_job_title_to_onet_code()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
